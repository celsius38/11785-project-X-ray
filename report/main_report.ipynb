{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/apple/Desktop/Study/Fall2018/11785/11785-project-X-ray/report\n"
     ]
    }
   ],
   "source": [
    "cd ../11785-project-X-ray/report/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_packed_sequence,pad_sequence,pack_padded_sequence,pack_sequence\n",
    "import sys\n",
    "\n",
    "from preprocess import INT_TO_CHAR, CHAR_TO_INT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/data.npy')\n",
    "findings = np.load('data/findings.npy')\n",
    "indications = np.load('data/indications.npy')\n",
    "impressions = np.load('data/impressions.npy')\n",
    "\n",
    "idx = np.arange(len(data))\n",
    "np.random.shuffle(idx)\n",
    "train_idx, dev_idx, test_idx = idx[:6000],idx[6000:6000+735],idx[6000+735:]\n",
    "\n",
    "train_x = data[train_idx]\n",
    "train_y = findings[train_idx]\n",
    "\n",
    "dev_x = data[dev_idx]\n",
    "dev_y = findings[dev_idx]\n",
    "\n",
    "test_x = data[test_idx]\n",
    "test_y = findings[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, label = None):\n",
    "        self._data = data\n",
    "        label = [np.append(y,0) for y in label]\n",
    "        self._label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        d =  self._data[index]\n",
    "        d = torch.from_numpy(d).float()\n",
    "        l = torch.tensor([0])\n",
    "        if self._label is not None:\n",
    "            l = torch.from_numpy(self._label[index]).long()\n",
    "        d, l = d.to(DEVICE), l.to(DEVICE)\n",
    "        return (d, l)\n",
    "    \n",
    "def collate_lines(batch):\n",
    "    batch = sorted(batch, key = lambda x: len(x[0]), reverse = True)\n",
    "    data = [b[0].unsqueeze(0) for b in batch] # B of (1, W, H)\n",
    "    target = [b[1] for b in batch] # B of (L, )\n",
    "    return torch.cat(data, dim = 0).unsqueeze(1), target #(B, 1, W, H), (B, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CustomDataset(train_x, train_y)\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=32, shuffle=True, collate_fn=collate_lines)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args[\"vocab_size\"] = 58\n",
    "args[\"lstm_hidden_size\"] = 512\n",
    "args[\"batch_size\"] = 32\n",
    "args[\"epochs\"] = 15\n",
    "args[\"num_workers\"] = 4\n",
    "args[\"image_embed_size\"] = 2048\n",
    "args[\"gpu\"] = True\n",
    "if (not torch.cuda.is_available()): args[\"gpu\"] = False\n",
    "args[\"label_cutoff\"] = 0.2 # minimum probability of a softmax output for a valid label\n",
    "args[\"k\"] = 4 # select top k softmax outputs as labels\n",
    "args[\"cnn_output_size\"] = 512\n",
    "args[\"char_embed_size\"] = 256\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "            padding=1, bias=False)    \n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.elu = nn.ELU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.elu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.elu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    tunable hyper parameters: embeddings\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        global args \n",
    "        super(ResNet, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "                nn.Conv2d(1,32,kernel_size = 5,padding = 0,stride = 2,bias = False),\n",
    "                nn.ELU(inplace=True),\n",
    "                BasicBlock(32,32), \n",
    "                nn.Conv2d(32,64,kernel_size = 5,padding = 0,stride = 2,bias = False),\n",
    "                nn.ELU(inplace=True),\n",
    "                BasicBlock(64,64),  \n",
    "                nn.Conv2d(64,128,kernel_size = 5,padding = 0,stride = 2,bias = False),\n",
    "                nn.ELU(inplace=True),\n",
    "                BasicBlock(128,128), \n",
    "                nn.Conv2d(128,512,kernel_size = 5,padding = 0,stride = 2,bias = False),\n",
    "                nn.ELU(inplace=True),\n",
    "                BasicBlock(512,512),\n",
    "                nn.AdaptiveAvgPool2d((2,2))\n",
    "        )\n",
    "        self.fc = nn.Linear(args[\"image_embed_size\"], args['cnn_output_size'], bias = False) \n",
    "#         self.sm = torch.nn.Softmax(dim = 1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def l2_normalization(self, x):\n",
    "        input_size = x.size()\n",
    "        buffer = torch.pow(x, 2)\n",
    "        norm = torch.sqrt(torch.sum(buffer, 1).add_(1e-10))\n",
    "        temp = torch.div(x, norm.view(-1, 1).expand_as(x))\n",
    "        x_l2 = temp.view(input_size)\n",
    "        return x_l2\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.network(x)\n",
    "        out = out.view(out.size(0), -1) # flatten to N x E\n",
    "        out = self.l2_normalization(out)\n",
    "        out = self.fc(out) \n",
    "#         out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XrayNet(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, hidden_size, max_len = 250):\n",
    "        global args \n",
    "        super(XrayNet, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.char_embed_size = args['char_embed_size'] \n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_len = max_len\n",
    "        self.embedding = nn.Embedding(self.vocab_size,self.char_embed_size) # Embedding layer    \n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "        self.lstmcell = nn.LSTMCell(input_size = self.char_embed_size, hidden_size = hidden_size)\n",
    "        self.lstmcell2 = nn.LSTMCell(input_size = hidden_size, hidden_size = hidden_size)\n",
    "        self.character_distribution = nn.Linear(hidden_size, vocab_size) # Projection layer\n",
    "#         self.dropout = LockedDropout()        \n",
    "     \n",
    "    # Stepwise operation of each sequence\n",
    "    def forward_step(self, input_step, hidden_cell_state, hidden_cell_state2): \n",
    "        embed = self.embedding(input_step)\n",
    "        hidden_state, cell_state = self.lstmcell(embed, hidden_cell_state) # s_i\n",
    "        hidden_state2, cell_state2 = self.lstmcell2(hidden_state, hidden_cell_state2) # s_i\n",
    "        raw_pred = self.softmax(self.character_distribution(hidden_state2))\n",
    "        return  raw_pred, (hidden_state, cell_state), (hidden_state2, cell_state2)\n",
    "    \n",
    "    def forward(self, cnn_output, mode = \"train\", ground_truth = None, ground_truth_len = None, teacher_force = 1): \n",
    "        if ground_truth is None:\n",
    "            step_size = self.max_len\n",
    "            \n",
    "        else:\n",
    "            ground_truth_len = torch.tensor([len(g) for g in ground_truth])\n",
    "            ground_truth_pad = rnn.pad_sequence(ground_truth, batch_first = True) # B * L\n",
    "            step_size = ground_truth_pad.size(1)\n",
    "\n",
    "        raw_pred_seq = []\n",
    "        output_seq = []\n",
    "        score = 0\n",
    "        batch_size = cnn_output.size(0)\n",
    "        cell_state = cnn_output\n",
    "        hidden_state = torch.zeros(cell_state.shape).to(DEVICE)\n",
    "        hidden_cell_state = (hidden_state, cell_state) # B x hidden\n",
    "        hidden_cell_state2 = None\n",
    "        \n",
    "        if ground_truth is not None:\n",
    "            input_step = ground_truth_pad[:,0]\n",
    "        else:\n",
    "#             input_step = torch.zeros(batch_size)  # (B, )\n",
    "            input_step = torch.LongTensor([0 for i in range(batch_size)]).to(DEVICE)\n",
    "        \n",
    "        score = 0\n",
    "        for step in range(step_size-1):\n",
    "            \n",
    "            raw_pred, hidden_cell_state, hidden_cell_state2 = self.forward_step(input_step, hidden_cell_state, hidden_cell_state2)\n",
    "            \n",
    "            # if train\n",
    "            if mode == \"train\":\n",
    "                raw_pred_seq.append(raw_pred.unsqueeze(1))\n",
    "\n",
    "            elif mode == \"dev\":\n",
    "                output = raw_pred.max(dim = 1)[1]\n",
    "                raw_pred_seq.append(output.unsqueeze(1)) #(B, 1)\n",
    "                if output.item() == 1:\n",
    "                    break\n",
    "            else:\n",
    "                ######## greedy ############\n",
    "#                 output = raw_pred.max(dim = 1)[1]\n",
    "#                 raw_pred_seq.append(output.unsqueeze(1)) #(B, 1)\n",
    "#                 if output.item() == 1:\n",
    "#                     break\n",
    "                #############################\n",
    "  \n",
    "                ######### random #############\n",
    "                \n",
    "                dist = torch.distributions.Categorical(logits = raw_pred) #(B, ttl_char)\n",
    "                output = dist.sample() # (B, )\n",
    "                score += raw_pred[0][output.item()]\n",
    "                raw_pred_seq.append(output.unsqueeze(1)) #(B, 1)\n",
    "                if output.item() == 1:\n",
    "                    break\n",
    "                ##############################\n",
    "            \n",
    "            if mode == \"train\" and np.random.rand() < teacher_force:\n",
    "                input_step = ground_truth_pad[:,step+1]\n",
    "            else:\n",
    "                input_step = raw_pred.max(dim = 1)[1]\n",
    "            \n",
    "        pred_seq = torch.cat(raw_pred_seq,dim=1)  # matrix\n",
    "        if mode == \"train\":\n",
    "            pred_seq = torch.cat([pred_seq[i,:ground_truth_len[i]-1,:] for i in range(batch_size)],dim=0)\n",
    "        elif mode == \"dev\":\n",
    "            pred_seq = torch.cat([pred_seq[i,:ground_truth_len[i]-1] for i in range(batch_size)],dim=0)\n",
    "        return pred_seq, score/len(pred_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-52b4b1ac4bae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# lists, presorted, preloaded on GPU    # Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Input shape: B x C x H x W = 32 x 1 x 512 x 512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-07243bc2a5eb>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn = ResNet().to(DEVICE) # image \n",
    "lstm = XrayNet(args[\"vocab_size\"], args[\"lstm_hidden_size\"]).to(DEVICE) # report\n",
    "optimizer = torch.optim.Adam([{'params':cnn.parameters()}, {'params':lstm.parameters()}],lr = 1e-4)\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "total_loss = 0\n",
    "for batch_id,(inputs,targets) in enumerate(train_loader): # lists, presorted, preloaded on GPU    # Load data\n",
    "    optimizer.zero_grad()\n",
    "    # Input shape: B x C x H x W = 32 x 1 x 512 x 512\n",
    "    cnn_out = cnn(inputs)\n",
    "     # Output shape: B x Hidden_size = 32 x 512\n",
    "    pred_y, _ = lstm(cnn_out, mode = \"train\", ground_truth = targets) #, teacher_force = 0.9)\n",
    "    true_y = torch.cat([y[1:] for y in targets])\n",
    "    loss = criterion(pred_y,true_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, cnn, lstm, optimizer, criterion, DEVICE):\n",
    "    global args\n",
    "    cnn, lstm = cnn.train(), lstm.train()\n",
    "    total_loss = 0\n",
    "    for batch_id,(inputs,targets) in enumerate(train_loader): # lists, presorted, preloaded on GPU    # Load data\n",
    "        if len(targets) == 0:\n",
    "            continue\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        # Input shape: B x C x H x W = 32 x 1 x 512 x 512\n",
    "        cnn_out = cnn(inputs)\n",
    "         # Output shape: B x Hidden_size = 32 x 512\n",
    "        pred_y, _ = lstm(cnn_out, mode = \"train\", ground_truth = targets) #, teacher_force = 0.9)\n",
    "        true_y = torch.cat([y[1:] for y in targets])\n",
    "        loss = criterion(pred_y,true_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_id % 500 == 0:\n",
    "            lpw = loss.item() \n",
    "            print(\"At batch\",batch_id)\n",
    "            print(\"Training loss per word:\",lpw)\n",
    "            print(\"Training perplexity :\",np.exp(lpw))\n",
    "        total_loss += lpw \n",
    "    return total_loss, cnn, lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'mat2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cc8309ab7457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" training loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-e66b46675117>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, cnn, lstm, optimizer, criterion, DEVICE)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcnn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m          \u001b[0;31m# Output shape: B x Hidden_size = 32 x 512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, teacher_force = 0.9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtrue_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrue_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-12fab43cce0d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, cnn_output, mode, ground_truth, ground_truth_len, teacher_force)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mraw_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_cell_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_cell_state2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_cell_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_cell_state2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# if train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-12fab43cce0d>\u001b[0m in \u001b[0;36mforward_step\u001b[0;34m(self, input_step, hidden_cell_state, hidden_cell_state2)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#         concat_embed = torch.cat([embed,context],dim=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstmcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_cell_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# s_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m#         hidden_state = self.dropout(hidden_state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m         )\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0migates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mhgates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfusedBackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMFused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0migates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhgates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mb_ih\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0migates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhgates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'mat2'"
     ]
    }
   ],
   "source": [
    "# use findings \n",
    "\n",
    "cnn = ResNet().to(DEVICE) # image \n",
    "lstm = XrayNet(args[\"vocab_size\"], args[\"lstm_hidden_size\"]).to(DEVICE) # report\n",
    "optimizer = torch.optim.Adam([{'params':cnn.parameters()}, {'params':lstm.parameters()}],lr = 1e-4)\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "\n",
    "best_distance = float(\"inf\")\n",
    "\n",
    "for epoch in range(1):\n",
    "    loss, cnn, lstm = train(train_loader, cnn, lstm, optimizer, criterion, DEVICE)\n",
    "    print('='*100)\n",
    "    print(epoch,\" training loss:\", loss)\n",
    "\n",
    "    if epoch%1 == 0: \n",
    "        distance = validation(dev_loader, cnn, lstm, DEVICE)\n",
    "        print(epoch,\" validation distance:\", distance)\n",
    "        \n",
    "    if distance < best_distance:\n",
    "        torch.save(cnn.state_dict(),'./cnn_'+str(epoch) + '.pt')\n",
    "        torch.save(lstm.state_dict(),'./lstm_'+str(epoch) + '.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_test(net, val_set):\n",
    "    global args\n",
    "    net = net.eval()\n",
    "    with torch.no_grad():\n",
    "        total_iou = 0\n",
    "        for batch_index, (batch_data, batch_label) in enumerate(tqdm(val_set)):\n",
    "            if args[\"gpu\"]:\n",
    "                batch_data = batch_data.cuda()\n",
    "            out = net(batch_data)\n",
    "            out = out.detach().cpu()\n",
    "            top_k, indices = torch.topk(out, k=args[\"k\"], dim=1) # top k max classes\n",
    "            out.zero_()\n",
    "            out.scatter_(1, indices, top_k)     # clip non-top-k to be zero\n",
    "            out[out < args[\"label_cutoff\"]] = 0 # clip those non-exceeding threshold to be zero\n",
    "            out = out.numpy()\n",
    "            # remove No Finding from pred if necessary\n",
    "            np.apply_along_axis(remove_null, 1, out)\n",
    "            pred_one_hot = torch.from_numpy(out)\n",
    "            batch_iou = iou(pred_one_hot, batch_label) # average iou score over a batch\n",
    "            total_iou += batch_iou\n",
    "        acc = total_iou/((batch_index+1)*args[\"batch_size\"])# average iou\n",
    "        print(\"Acc: {}\".format(acc))\n",
    "        return acc\n",
    "\n",
    "def train_val(net, train_set, val_set):\n",
    "    global args\n",
    "    # criterion = CustomLoss()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = 1e-3, betas = (0.9, 0.999))\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "            mode = \"max\", factor = 0.1, patience = 1) #reduce lr once acc stop increasing\n",
    "    if args[\"gpu\"]:\n",
    "        net = net.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    best_acc = -float(\"inf\")\n",
    "    train_loss = []; val_acc = []\n",
    "    for epoch in range(args[\"epochs\"]):\n",
    "        # train\n",
    "        loss = train(net, epoch, train_set, criterion, optimizer)\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        # validation\n",
    "        acc = val_test(net, val_set)\n",
    "        val_acc.append(acc)\n",
    "\n",
    "        # step learning rate\n",
    "        scheduler.step(acc)\n",
    "\n",
    "        # save model if best\n",
    "        if acc > best_acc:\n",
    "            print(\"crt: {}, best: {}, saving...\".format(acc, best_acc))\n",
    "            best_acc = acc\n",
    "            torch.save(net, \"epoch{}\".format(epoch))\n",
    "    return train_loss, val_acc\n",
    "\n",
    "def main():\n",
    "\n",
    "    # load train and val set\n",
    "    train_set = preprocess.get_traindata(args[\"batch_size\"], args[\"num_workers\"])\n",
    "    val_set = preprocess.get_valdata(args[\"batch_size\"], args[\"num_workers\"])\n",
    "\n",
    "    # get net and train\n",
    "    # net = torch.load(\"\")\n",
    "    net = XrayNet()\n",
    "    train_loss, val_acc = train_val(net, train_set, val_set)\n",
    "\n",
    "    # test\n",
    "    test_set = preprocess.get_testdata(args[\"batch_size\"], args[\"num_workers\"])\n",
    "    val_test(net, test_set)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
